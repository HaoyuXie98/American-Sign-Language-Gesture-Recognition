This project leverageS deep learning techniques for the recognition of American Sign Language (ASL) to enhance communication opportunities for individuals with disabilities. We trained an ASL dataset through the PyTorch framework for three distinct models, ResNet, SqueezeNet, and a self-build model. By comparing the models and fine-tuning their parameters, we identified the optimal architecture for ASL recognition. We also developed a website for American Sign Language Detection, which captures users' signs through camera input and utilizes the Text-to-Speech API to convert the recognized ASL gestures into audible speech.

Here is a demo video: https://youtu.be/A4KWUR5Q4lM
